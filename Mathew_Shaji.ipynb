{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5e9df5",
   "metadata": {},
   "source": [
    "# Deep Learning to Classify images\n",
    "\n",
    "\n",
    "Deep learning (also known as deep structured learning) is a machine learning system that uses artificial neural networks to learn representations. Supervised, semi-supervised, and unsupervised learning are all possible options.\n",
    "\n",
    "Here in This project, Every picture has a cell nucleus in the centre. The ultimate aim for this data science project is to train a deep neural network that can classify a 64x64 image with a cell nucleus in the centre into one of the following forms:\n",
    "\n",
    "1. Normal epithelial cells.\n",
    "2. Cancer epithelial cells.\n",
    "3. Immune Leukocyte cells .\n",
    "4. Connective fibroblast cells ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf86c6a",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f12caa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e92c628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Id     Image         Type  Labels\n",
       "0        1     1.png   Connective       1\n",
       "1        2     2.png   Connective       1\n",
       "2        3     3.png   Connective       1\n",
       "3        4     4.png   Connective       1\n",
       "4        5     5.png   Connective       1\n",
       "...    ...       ...          ...     ...\n",
       "2185  2186  2186.png       Immune       2\n",
       "2186  2187  2187.png       Cancer       0\n",
       "2187  2188  2188.png   Connective       1\n",
       "2188  2189  2189.png   Connective       1\n",
       "2189  2190  2190.png       Immune       2\n",
       "\n",
       "[2190 rows x 4 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file path\n",
    "path = 'deep-learning-for-msc-coursework-2021/'\n",
    "\n",
    "# creating dataframe\n",
    "\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "train_df['Image'] = train_df['Id'].astype(str) + '.png'\n",
    "train_df = train_df[train_df.columns[[0, 2, 1]]]\n",
    "train_df['Type'] = train_df['Type'].astype('category')\n",
    "train_df['Labels'] = train_df['Type'].cat.codes\n",
    "\n",
    "train_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df6c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d33f210",
   "metadata": {},
   "source": [
    "###  Creating Class Structure to apply transformation to training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa0d75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIDataset(Dataset):\n",
    "    def __init__(self, data_frame, image_dir, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image_name  = os.path.join(self.image_dir, self.data_frame.iloc[idx, 1])\n",
    "        images = read_image(image_name)\n",
    "        labels = torch.from_numpy(np.array(self.data_frame.iloc[idx, -1])).long()\n",
    "        images = images.type(torch.FloatTensor)\n",
    "        images = images / 255.0\n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "            \n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af55ed",
   "metadata": {},
   "source": [
    "## Data Augumentation\n",
    "\n",
    "Data augmentation, which involves randomly transforming the training images, such as flipping, rotating, or cropping them, is one way to mitigate the overfitting problem.\n",
    "\n",
    "Since these data augmentation transformations are implemented at random during training, the same image can be interpreted differently from batch to batch, resulting in more variety in the training data and assisting in the development of new tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8605b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e51363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIDataset(\n",
    "    data_frame = train_df,\n",
    "    image_dir = path + 'train/train',\n",
    "    transform = train_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aebffc",
   "metadata": {},
   "source": [
    "## Modeling Neural Network\n",
    "A CNN's central building block is the convolutional layer. The parameters of the layer are made up of a series of learnable filters (or kernels) with a limited receptive field but that span the entire depth of the input volume.\n",
    "\n",
    "Each filter is convolved across the width and height of the input volume during the forward transfer, computing the dot product between the filter's entries and the input, and generating a 2-dimensional activation map for that filter. As a consequence, the network learns filters that activate when it detects a certain form of feature at a particular spatial location in the input.\n",
    "\n",
    "\n",
    "We have three convolution layers and three linear layers in this model. Each layer has a Relu activation function added to it to make it non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f8389f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,kernel_size=3,out_channels=16,stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,kernel_size=3,out_channels=64,stride=1,padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,kernel_size=3,out_channels=128,stride=1,padding=1)\n",
    "        #self.conv4 = nn.Conv2d(in_channels=128,kernel_size=3,out_channels=256,stride=1,padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*128, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 4)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c62f4",
   "metadata": {},
   "source": [
    "### Loading train data using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "463142a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbda00",
   "metadata": {},
   "source": [
    "### Checking for Availability of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8155b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "print (cuda_avail)\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b2340",
   "metadata": {},
   "source": [
    "### Creating Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3f6e79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "model = cnNet()\n",
    "if cuda_avail:\n",
    "    model.cuda()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ec8e4",
   "metadata": {},
   "source": [
    "### Adjusting Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35baa6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the learning rate based on number of epochs\n",
    "\n",
    "def adjust_learning_rate(epoch):\n",
    "    lr = 0.001\n",
    "    if epoch > 55:\n",
    "        lr = lr/10000\n",
    "    if epoch > 50:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 45:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 35:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 20:\n",
    "        lr = lr / 10\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7997d78",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e53b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \t Loss:0.62451327 \t Train accuracy: 48.767%\n",
      "Epoch:5 \t Loss:0.66178089 \t Train accuracy: 72.100%\n",
      "Epoch:10 \t Loss:0.58386821 \t Train accuracy: 77.671%\n",
      "Epoch:15 \t Loss:0.45930877 \t Train accuracy: 80.502%\n",
      "Epoch:20 \t Loss:0.46861848 \t Train accuracy: 82.283%\n",
      "Epoch:25 \t Loss:0.54915631 \t Train accuracy: 86.941%\n",
      "Epoch:30 \t Loss:0.22757420 \t Train accuracy: 88.767%\n",
      "Epoch:35 \t Loss:0.11863355 \t Train accuracy: 90.183%\n",
      "Epoch:40 \t Loss:0.17650083 \t Train accuracy: 90.959%\n",
      "Epoch:45 \t Loss:0.34122354 \t Train accuracy: 90.776%\n",
      "Epoch:50 \t Loss:0.20314768 \t Train accuracy: 91.735%\n",
      "Epoch:55 \t Loss:0.10339920 \t Train accuracy: 91.005%\n",
      "Epoch:60 \t Loss:0.50156283 \t Train accuracy: 91.279%\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "n_epoch = 5\n",
    "\n",
    "train_losses = []\n",
    "train_correct = []\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(1, epochs +1):\n",
    "    train_acc = 0\n",
    "    \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "       \n",
    "        y_pred = model(X_train.to(device))\n",
    "        loss = loss_fn(y_pred, y_train.to(device))\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        train_acc += (predicted == y_train.to(device)).sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    adjust_learning_rate(i)\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    acc = train_acc.item()*100/2190\n",
    "    train_correct.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "    \n",
    "    if i ==1 or i % n_epoch == 0:\n",
    "        print(f'Epoch:{i} \\t Loss:{loss.item():10.8f} \\t Train accuracy:{acc:7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1df65",
   "metadata": {},
   "source": [
    "### Loading the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3140911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'deep-learning-for-msc-coursework-2021/'\n",
    "valid_dataset = datasets.ImageFolder(os.path.join(root, 'test'), transform=test_transform)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455b284",
   "metadata": {},
   "source": [
    "### Predicting the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "618de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id        Type\n",
      "0    10001  Connective\n",
      "1    10002  Connective\n",
      "2    10003  Connective\n",
      "3    10004      Immune\n",
      "4    10005  Connective\n",
      "..     ...         ...\n",
      "395  10396      Cancer\n",
      "396  10397      Cancer\n",
      "397  10398      Cancer\n",
      "398  10399      Cancer\n",
      "399  10400      Normal\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "diseases = ['Cancer', 'Connective', 'Immune', 'Normal']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# loading the best model parameters\n",
    "model.load_state_dict(torch.load('best-model.pt'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in valid_loader:\n",
    "        out = model(images.to(device))\n",
    "        predicted = torch.max(out.data, 1)[1]\n",
    "        predictions.append(predicted)\n",
    "predictions = torch.cat(predictions)\n",
    "id = np.arange(10001, 10401)\n",
    "type = np.array([diseases[i] for i in predictions])\n",
    "dict = {'Id': id, 'Type': type}\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv('test.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29688b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(train_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e7f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2462f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
